{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q datasets\n!pip install -q scipy\n!pip install -U accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T22:54:55.300624Z","iopub.execute_input":"2024-05-27T22:54:55.301183Z","iopub.status.idle":"2024-05-27T22:57:36.996364Z","shell.execute_reply.started":"2024-05-27T22:54:55.301148Z","shell.execute_reply":"2024-05-27T22:57:36.995230Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.31.0.dev0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Load the tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"guardrail/llama-2-7b-guanaco-instruct-sharded\")\nmodel = AutoModelForCausalLM.from_pretrained(\"guardrail/llama-2-7b-guanaco-instruct-sharded\")\n\n# Define the input prompt\ninput_text = \"Hello\"\n\n# Tokenize the input\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n\n# Generate the output using the model\noutput = model.generate(input_ids, max_length=50)\n\n# Decode the generated output\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(generated_text)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:02:22.603170Z","iopub.execute_input":"2024-05-27T23:02:22.604379Z","iopub.status.idle":"2024-05-27T23:07:31.280110Z","shell.execute_reply.started":"2024-05-27T23:02:22.604339Z","shell.execute_reply":"2024-05-27T23:07:31.279136Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76e84e978be34fddb44d5f052fe0b050"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66e71bd0a4c42ee893fcc68943f7e16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bbb4a7f30924ecd834eb1b20304a38b"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63b2ad0dd43c49cca6000e60b4011d4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132d401838dd4a87937805bf32404f8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7d61c4c542044d7b4aa059ea6a312ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00014.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33cb1440b174d10902650825761f3d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eca61b157e34328b60fe49c7abf7330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45c9300bc8474a7188d87bbf0b15ac5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00014.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f345772fbbf94aa3ae340302312f44e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00014.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"783b40a517f745d789c713670645b209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00014.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9dfd6a14da146c69e3106a9287d35c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61e97a67499043afb48160d024b4ac7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"effd37781ea14a64a2691a279a5e8a4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00014.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67cd8f427c0c47e8806117ad0919e717"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00014.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e37557aae154ca29c41b151ed3ce7e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00014.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c741dd38d5407db5abbe7018a5d321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00012-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2b2f698fdd242f78ed09888c9850d47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00013-of-00014.safetensors:   0%|          | 0.00/1.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568578649de24f728e8b56f81a88d711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00014-of-00014.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10fa4c14456479ab0070dc8258a4133"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c863d781f054d38b79b04aa88bbbc50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2df30768b6534b99817367f8b5d6e0ec"}},"metadata":{}},{"name":"stdout","text":"Hello, I am interested in [Bedroom with Private Balcony and Sea Views]\n\nI am looking for a bedroom with a private balcony and sea views in a quiet and peaceful area. The room should\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Dá»‹ch sÆ° tá»­ sang tiáº¿ng nga\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=100)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:07:31.281750Z","iopub.execute_input":"2024-05-27T23:07:31.282188Z","iopub.status.idle":"2024-05-27T23:09:28.344017Z","shell.execute_reply.started":"2024-05-27T23:07:31.282159Z","shell.execute_reply":"2024-05-27T23:09:28.342891Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Dá»‹ch sÆ° tá»­ sang tiáº¿ng nga\n\nTiáº¿ng Nga cÃ³ nhiá»u tá»« vá»±ng vÃ  cáº¥u trÃºc khÃ¡c biá»‡t so vá»›i tiáº¿ng Viá»‡t, nÃªn cáº§n pháº£i Ä‘áº·t tÃªn riÃªng cho má»—i tá»« vá»±ng Ä‘á»ƒ Ä‘Æ°á»£c chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Äá» xuáº¥t 1 cuá»‘n sÃ¡ch hay\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:09:28.345419Z","iopub.execute_input":"2024-05-27T23:09:28.345845Z","iopub.status.idle":"2024-05-27T23:13:20.751757Z","shell.execute_reply.started":"2024-05-27T23:09:28.345807Z","shell.execute_reply":"2024-05-27T23:13:20.750715Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Äá» xuáº¥t 1 cuá»‘n sÃ¡ch hay cho cÃ¡c em há»c sinh lá»›p 10\n\nChapter 1: Introduction to the Book\n\nIntroduction:\n\n* The book is about the importance of learning English for students in Vietnam.\n* The author argues that English is a global language and essential for success in today's world.\n* The book provides practical tips and strategies for learning English.\n\nChapter 2: The Benefits of Learning English\n\n* English is a global language and essential for success in today's world.\n* Knowing English can open up new opportunities for students in Vietnam.\n* English can help students to communicate with people from different cultures and backgrounds.\n\nChapter 3: How to Learn English\n\n* The book provides practical tips and strategies for learning English.\n* The author suggests that students should start by learning basic vocabulary and grammar.\n* The book also\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Ä‚n gÃ¬ Ä‘á»ƒ khá»e máº¡nh?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:13:20.754746Z","iopub.execute_input":"2024-05-27T23:13:20.755293Z","iopub.status.idle":"2024-05-27T23:17:13.802458Z","shell.execute_reply.started":"2024-05-27T23:13:20.755254Z","shell.execute_reply":"2024-05-27T23:17:13.801489Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Ä‚n gÃ¬ Ä‘á»ƒ khá»e máº¡nh?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"CÃ³ nÃªn lÃ m viá»‡c online khÃ´ng?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:17:13.803979Z","iopub.execute_input":"2024-05-27T23:17:13.804359Z","iopub.status.idle":"2024-05-27T23:21:06.592968Z","shell.execute_reply.started":"2024-05-27T23:17:13.804326Z","shell.execute_reply":"2024-05-27T23:21:06.591918Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"CÃ³ nÃªn lÃ m viá»‡c online khÃ´ng?\n\nCÃ³ nÃªn lÃ m viá»‡c online khÃ´ng? ÄÃ¢y lÃ  má»™t cÃ¢u há»i phá»• biáº¿n Ä‘Æ°á»£c Ä‘Æ°a ra bá»Ÿi nhiá»u ngÆ°á»i trong giá»›i tráº». Tuy nhiÃªn, Ä‘á»ƒ Ä‘Ã¡p Ä‘Æ°á»£c cÃ¢u há»i nÃ y, cáº§n pháº£i xem xÃ©t tá»«ng bÆ°á»›c vÃ  Ä‘Ã¡nh giÃ¡ tá»«ng ngÆ°á»i.\nFirstly, it is important to understand that working online is not for everyone. Some people may prefer the structure and routine of a traditional office environment, or they may have difficulty staying focused and motivated when working from home. Additionally, some jobs may not be suitable for remote work, such\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Viáº¿t 1 cÃ¢u chia buá»“n vá»›i ngÆ°á»i báº¡n thÃ¢n\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:21:06.594439Z","iopub.execute_input":"2024-05-27T23:21:06.594931Z","iopub.status.idle":"2024-05-27T23:24:59.431556Z","shell.execute_reply.started":"2024-05-27T23:21:06.594894Z","shell.execute_reply":"2024-05-27T23:24:59.430516Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Viáº¿t 1 cÃ¢u chia buá»“n vá»›i ngÆ°á»i báº¡n thÃ¢n nháº¥t cá»§a mÃ¬nh, Ã´ng Háº£i, vÃ o ngÃ y 10 thÃ¡ng 3 nÄƒm 1968.\n\n---\n\n\"Hey, Háº£i! *hug* I'm so glad we're finally hanging out again! It's been ages since we last saw each other. *smile* I know we've both been busy with work and stuff, but it's great to have some time to catch up. *nod* So, what have you been up to lately? Any new projects or adventures? *curious* Tell me everything! *excited* Oh, and by the way, I've been meaning to ask you... *pauses* Do you remember that time we went to that crazy karaoke bar and sang 'I Will Survive' together? *laugh\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \" Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  gÃ¬? \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:24:59.432800Z","iopub.execute_input":"2024-05-27T23:24:59.433079Z","iopub.status.idle":"2024-05-27T23:25:59.610392Z","shell.execute_reply.started":"2024-05-27T23:24:59.433055Z","shell.execute_reply":"2024-05-27T23:25:59.609426Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":" Thá»§ Ä‘Ã´ cá»§a Viá»‡t Nam lÃ  gÃ¬? \n\nA. HÃ  Ná»™i\nB. Há»“ ChÃ­ Minh City\nC. ÄÃ  Náºµng\nD. Cáº§n ThÆ¡\n\nAnswer: A. HÃ  Ná»™i\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \" TrÃ¡i Ä‘áº¥t cÃ³ bao nhiÃªu chÃ¢u lá»¥c?  \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:25:59.611709Z","iopub.execute_input":"2024-05-27T23:25:59.612079Z","iopub.status.idle":"2024-05-27T23:28:22.992985Z","shell.execute_reply.started":"2024-05-27T23:25:59.612043Z","shell.execute_reply":"2024-05-27T23:28:22.992040Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":" TrÃ¡i Ä‘áº¥t cÃ³ bao nhiÃªu chÃ¢u lá»¥c?  \n\nTrÃ¡i Ä‘áº¥t cÃ³ bao nhiÃªu chÃ¢u lá»¥c?\n\nThe Earth has 7 continents.\n\nThe 7 continents are:\n\n1. Africa\n2. Antarctica\n3. Asia\n4. Australia\n5. Europe\n6. North America\n7. South America\n\nNote: Some sources may group Europe and Asia together as a single continent, Eurasia, or combine North and South America as the Americas. However, the 7-continent model is the most commonly used.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \" Ai lÃ  ngÆ°á»i phÃ¡t minh ra bÃ³ng Ä‘Ã¨n?  \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:28:22.994120Z","iopub.execute_input":"2024-05-27T23:28:22.994408Z","iopub.status.idle":"2024-05-27T23:32:16.132117Z","shell.execute_reply.started":"2024-05-27T23:28:22.994382Z","shell.execute_reply":"2024-05-27T23:32:16.130790Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":" Ai lÃ  ngÆ°á»i phÃ¡t minh ra bÃ³ng Ä‘Ã¨n?  \n\nAi lÃ  ngÆ°á»i phÃ¡t minh ra bÃ³ng Ä‘Ã¨n?\n\nNgÆ°á»i ta biáº¿t ráº±ng Ai lÃ  ngÆ°á»i phÃ¡t minh ra bÃ³ng Ä‘Ã¨n, nhÆ°ng chÃ­nh xÃ¡c hÆ¡n thÃ¬ Ai chá»‰ lÃ  ngÆ°á»i phÃ¡t minh ra bÃ³ng Ä‘Ã¨n Ä‘iá»‡n.\nBÃ³ng Ä‘Ã¨n Ä‘iá»‡n Ä‘Æ°á»£c phÃ¡t minh ra vÃ o nÄƒm 1879 bá»Ÿi Thomas Edison, má»™t nhÃ  khoa há»c Má»¹. Edison Ä‘Ã£ phÃ¡t triá»ƒn má»™t loáº¡i bÃ³ng Ä‘Ã¨n Ä‘iá»‡n sá»­ dá»¥ng than chÃ¬ Ä‘á»ƒ táº¡o ra \n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"NÆ°á»›c biá»ƒn cÃ³ vá»‹ gÃ¬?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:32:16.135335Z","iopub.execute_input":"2024-05-27T23:32:16.135635Z","iopub.status.idle":"2024-05-27T23:36:10.487479Z","shell.execute_reply.started":"2024-05-27T23:32:16.135608Z","shell.execute_reply":"2024-05-27T23:36:10.486482Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"NÆ°á»›c biá»ƒn cÃ³ vá»‹ gÃ¬?\n\nNÆ°á»›c biá»ƒn cÃ³ vá»‹ chua, vá»‹ Ä‘áº¯ng, vá»‹ máº·n, vá»‹ ngá»t...\n\nVá»‹ chua: NÆ°á»›c biá»ƒn cÃ³ vá»‹ chua Ä‘áº­m Ä‘Ã , Ä‘Æ°á»£c tá»« cÃ¡c cháº¥t dinh dÆ°á»¡ng nhÆ° axit chloride vÃ  axit sulfuric. Vá»‹ chua nÃ y cÃ³ thá»ƒ khiáº¿n ngÆ°á»i ta cáº£m tháº¥y khÃ³ chá»‹u vÃ  khÃ´ng thÃ­ch há»£p cho ngÆ°á»i Äƒn.\nVá»‹ Ä‘áº¯ng: NÆ°á»›c biá»ƒn cÃ³ vá»‹ Ä‘áº¯ng Ä‘áº­m Ä‘Ã , Ä‘Æ°á»£c tá»« cÃ¡c cháº¥t dinh dÆ°\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Máº·t trá»i má»c á»Ÿ hÆ°á»›ng nÃ o? \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:36:10.488827Z","iopub.execute_input":"2024-05-27T23:36:10.489166Z","iopub.status.idle":"2024-05-27T23:37:39.762026Z","shell.execute_reply.started":"2024-05-27T23:36:10.489138Z","shell.execute_reply":"2024-05-27T23:37:39.761057Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Máº·t trá»i má»c á»Ÿ hÆ°á»›ng nÃ o? ðŸŒž\n\nMáº·t trá»i má»c á»Ÿ hÆ°á»›ng Ä‘Ã´ng nam. ðŸŒž\n\nðŸ” TÃ¬m hiá»ƒu thÃªm: Máº·t trá»i má»c á»Ÿ hÆ°á»›ng nÃ o?\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Quá»‘c khÃ¡nh Viá»‡t Nam lÃ  ngÃ y nÃ o?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:37:39.763403Z","iopub.execute_input":"2024-05-27T23:37:39.763735Z","iopub.status.idle":"2024-05-27T23:41:32.529051Z","shell.execute_reply.started":"2024-05-27T23:37:39.763707Z","shell.execute_reply":"2024-05-27T23:41:32.527894Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Quá»‘c khÃ¡nh Viá»‡t Nam lÃ  ngÃ y nÃ o?\n\nQuá»‘c khÃ¡nh Viá»‡t Nam lÃ  ngÃ y 2 thÃ¡ng 9 nÄƒm 1945, khi Chá»§ tá»‹ch Há»“ ChÃ­ Minh tuyÃªn bá»‘ Ä‘á»™c láº­p tá»« PhÃ¡p. Tá»« Ä‘Ã³, Viá»‡t Nam trá»Ÿ thÃ nh má»™t nÆ°á»›c Ä‘á»™c láº­p vÃ  tá»± trá»‹.\nNgÃ y Quá»‘c khÃ¡nh Viá»‡t Nam Ä‘Æ°á»£c tá»• chá»©c hÃ ng nÄƒm vÃ o ngÃ y 2 thÃ¡ng 9, vÃ  Ä‘Æ°á»£c coi lÃ  má»™t ngÃ y lá»… quá»‘c gia. NgÃ y nÃ y cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng \n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Tháº¿ váº­n há»™i Olympic diá»…n ra bao nhiÃªu nÄƒm má»™t láº§n?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:41:32.530420Z","iopub.execute_input":"2024-05-27T23:41:32.530813Z","iopub.status.idle":"2024-05-27T23:41:51.548165Z","shell.execute_reply.started":"2024-05-27T23:41:32.530777Z","shell.execute_reply":"2024-05-27T23:41:51.547175Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Tháº¿ váº­n há»™i Olympic diá»…n ra bao nhiÃªu nÄƒm má»™t láº§n?\n\nThe Olympic Games take place every 4 years.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"CÃºp bÃ³ng Ä‘Ã¡ tháº¿ giá»›i gáº§n nháº¥t Ä‘Æ°á»£c tá»• chá»©c á»Ÿ Ä‘Ã¢u?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:41:51.549230Z","iopub.execute_input":"2024-05-27T23:41:51.549518Z","iopub.status.idle":"2024-05-27T23:42:19.283479Z","shell.execute_reply.started":"2024-05-27T23:41:51.549493Z","shell.execute_reply":"2024-05-27T23:42:19.282419Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CÃºp bÃ³ng Ä‘Ã¡ tháº¿ giá»›i gáº§n nháº¥t Ä‘Æ°á»£c tá»• chá»©c á»Ÿ Ä‘Ã¢u?\n\nThe most recent FIFA World Cup was held in Russia in 2018.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Ai lÃ  tá»•ng thá»‘ng hiá»‡n táº¡i cá»§a Hoa Ká»³?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:42:19.284744Z","iopub.execute_input":"2024-05-27T23:42:19.285049Z","iopub.status.idle":"2024-05-27T23:44:47.270154Z","shell.execute_reply.started":"2024-05-27T23:42:19.285023Z","shell.execute_reply":"2024-05-27T23:44:47.269066Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Ai lÃ  tá»•ng thá»‘ng hiá»‡n táº¡i cá»§a Hoa Ká»³?\n\nAi: Joe Biden\n\nTrong nÄƒm 2020, Joe Biden Ä‘Ã£ Ä‘Ã¡nh báº¡i Ä‘á»‘i thá»§ Donald Trump Ä‘á»ƒ trá»Ÿ thÃ nh Tá»•ng thá»‘ng thá»© 46 cá»§a Hoa Ká»³. Biden Ä‘Ã£ Ä‘Æ°á»£c báº§u vÃ o nÄƒm 2020 vÃ  Ä‘ang phá»¥c vá»¥ nhiá»‡m ká»³ thá»© hai cá»§a mÃ¬nh.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"Viáº¿t má»™t hÃ m Python in ra Hello, World!\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:44:47.271714Z","iopub.execute_input":"2024-05-27T23:44:47.272505Z","iopub.status.idle":"2024-05-27T23:48:39.588167Z","shell.execute_reply.started":"2024-05-27T23:44:47.272465Z","shell.execute_reply":"2024-05-27T23:48:39.587117Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Viáº¿t má»™t hÃ m Python in ra Hello, World!\n\nTrong Python, hÃ m lÃ  má»™t pháº§n cá»§a mÃ£ nguá»“n Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a Ä‘á»ƒ thá»±c thi má»™t hoáº·c nhiá»u lá»‡nh trong má»™t chuá»—i cÃ¡c lá»‡nh. HÃ m cÃ³ thá»ƒ Ä‘Æ°á»£c gá»i báº±ng tÃªn cá»§a nÃ³, vÃ  khi Ä‘Æ°á»£c gá»i, hÃ m sáº½ thá»±c thi cÃ¡c lá»‡nh trong nÃ³.\nVÃ­ dá»¥, Ä‘á»ƒ viáº¿t má»™t hÃ m Python Ä‘á»ƒ in ra \"Hello, World!\", báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng sau dÃ²ng mÃ£:\n```\ndef hello_\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"LÃ m tháº¿ nÃ o Ä‘á»ƒ cá»™ng hai sá»‘ trong Python? \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:48:39.589485Z","iopub.execute_input":"2024-05-27T23:48:39.589809Z","iopub.status.idle":"2024-05-27T23:51:42.088974Z","shell.execute_reply.started":"2024-05-27T23:48:39.589784Z","shell.execute_reply":"2024-05-27T23:51:42.088018Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"LÃ m tháº¿ nÃ o Ä‘á»ƒ cá»™ng hai sá»‘ trong Python? \n\n```\na = 5\nb = 3\n\n# Cá»™ng hai sá»‘\nresult = a + b\n\nprint(result) # Output: 8\n```\n\nIn this example, we define two variables `a` and `b` with values `5` and `3`, respectively. Then, we use the `+` operator to add them together and store the result in a new variable `result`. Finally, we print the value of `result` to the console.\nNote that in Python, the `+` operator performs addition for both integers and floating-point numbers. So, when we add `5` and `3`, the result is `8`, which is a floating-point number.\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"HTML lÃ  viáº¿t táº¯t cá»§a gÃ¬?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:51:42.090360Z","iopub.execute_input":"2024-05-27T23:51:42.091274Z","iopub.status.idle":"2024-05-27T23:55:36.242226Z","shell.execute_reply.started":"2024-05-27T23:51:42.091235Z","shell.execute_reply":"2024-05-27T23:55:36.241205Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"HTML lÃ  viáº¿t táº¯t cá»§a gÃ¬?\n\nHTML (HyperText Markup Language) lÃ  má»™t ngÃ´n ngá»¯ mÃ£ hÃ³a Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘áº·t cÃ¡c thÃ´ng tin trÃªn máº¡ng web. HTML Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘áº·t cÃ¡c thÃ´ng tin nhÆ° tÃªn, ná»™i dung, Ä‘á»‹a chá»‰ URL, áº£nh, video, v.v trÃªn máº¡ng web.\nHTML Ä‘Æ°á»£c viáº¿t báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c kÃ½ hiá»‡u vÃ  cÃ¡c thuá»™c tÃ­nh Ä‘á»ƒ mÃ£ hÃ³a cÃ¡c thÃ´ng tin. CÃ¡c kÃ½ hiá»‡u vÃ  thuá»™c tÃ­nh n\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"HÃ£y hÆ°á»›ng dáº«n cÃ¡ch lÃ m má»™t chiáº¿c bÃ¡nh mÃ¬ káº¹p\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:55:36.243412Z","iopub.execute_input":"2024-05-27T23:55:36.243732Z","iopub.status.idle":"2024-05-27T23:59:28.261461Z","shell.execute_reply.started":"2024-05-27T23:55:36.243707Z","shell.execute_reply":"2024-05-27T23:59:28.260386Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"HÃ£y hÆ°á»›ng dáº«n cÃ¡ch lÃ m má»™t chiáº¿c bÃ¡nh mÃ¬ káº¹p Ä‘Æ¡n giáº£n vÃ  ngon\n\nIngredients:\n\n* 2 cups of all-purpose flour\n* 1/4 teaspoon of salt\n* 1/4 teaspoon of sugar\n* 1/4 cup of warm water\n* 1/4 cup of vegetable oil\n* 1 egg, beaten\n* Sesame seeds or poppy seeds for topping (optional)\n\nInstructions:\n\n1. In a large mixing bowl, combine the flour, salt, and sugar.\n2. Gradually add the warm water to the flour mixture and mix until a dough forms.\n3. Add the vegetable oil and mix until the dough is smooth and elastic.\n4. Knead the dough for 5-10 minutes until it becomes soft and pliable.\n5. Cover\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"LÃ m tháº¿ nÃ o Ä‘á»ƒ lÃ m bÃ i táº­p vá» nhÃ ? \"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T23:59:28.263257Z","iopub.execute_input":"2024-05-27T23:59:28.263619Z","iopub.status.idle":"2024-05-28T00:03:19.759810Z","shell.execute_reply.started":"2024-05-27T23:59:28.263585Z","shell.execute_reply":"2024-05-28T00:03:19.758791Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"LÃ m tháº¿ nÃ o Ä‘á»ƒ lÃ m bÃ i táº­p vá» nhÃ ? 10 cÃ¡ch Ä‘Æ¡n giáº£n Ä‘á»ƒ bÃ i táº­p táº¡i nhÃ \n\n1. BÃ i táº­p trÃªn mÃ n hÃ¬nh: Äá»ƒ bÃ i táº­p táº¡i nhÃ , báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng mÃ n hÃ¬nh cá»§a mÃ¬nh Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c ká»¹ thuáº­t vÃ  cÃ¡c cÃ¢u há»i. Báº¡n cÃ³ thá»ƒ tÃ¬m kiáº¿m cÃ¡c video bÃ i táº­p trÃªn YouTube hoáº·c cÃ¡c trang web khÃ¡c Ä‘á»ƒ há»c vÃ  thá»±c hiá»‡n cÃ¡c ká»¹ thuáº­t.\n2. BÃ i táº­p trÃªn cÃ¡c thiáº¿t bá»‹: Náº¿u\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"LÃ m tháº¿ nÃ o Ä‘á»ƒ gá»­i má»™t email?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=200)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T00:03:19.761131Z","iopub.execute_input":"2024-05-28T00:03:19.761949Z","iopub.status.idle":"2024-05-28T00:07:12.060834Z","shell.execute_reply.started":"2024-05-28T00:03:19.761919Z","shell.execute_reply":"2024-05-28T00:07:12.059743Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"LÃ m tháº¿ nÃ o Ä‘á»ƒ gá»­i má»™t email?\n\nYou can send an email in a few different ways, depending on your needs and preferences. Here are some common methods:\n\n1. Using an email client: You can use an email client such as Microsoft Outlook, Mozilla Thunderbird, or Apple Mail to compose and send an email. These clients allow you to create and send emails with ease.\n2. Using a web-based email service: Many email providers, such as Gmail, Yahoo Mail, or Outlook.com, offer web-based email services that allow you to compose and send emails directly from a web browser.\n3. Using a mobile app: Many email providers also offer mobile apps that allow you to compose and send emails from your smartphone or tablet.\n4. Using a third-party email service: There are many third-party email services available, such as Mailchimp or Constant Contact, that allow you to create and send emails with more advanced\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"HÃ£y hÆ°á»›ng dáº«n cÃ¡ch gáº¥p má»™t con háº¡c giáº¥y.\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=300)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T00:07:12.062213Z","iopub.execute_input":"2024-05-28T00:07:12.062875Z","iopub.status.idle":"2024-05-28T00:11:20.948886Z","shell.execute_reply.started":"2024-05-28T00:07:12.062835Z","shell.execute_reply":"2024-05-28T00:11:20.947909Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"HÃ£y hÆ°á»›ng dáº«n cÃ¡ch gáº¥p má»™t con háº¡c giáº¥y.\n\nCÃ¡ch gáº¥p má»™t con háº¡c giáº¥y:\n\nStep 1: Cut out a square of paper.\nStep 2: Fold the square in half diagonally to create a triangle.\nStep 3: Fold the triangle in half again to create a smaller triangle.\nStep 4: Fold the smaller triangle in half again to create an even smaller triangle.\nStep 5: Continue folding the triangle in half until you have a long, thin strip of paper.\nStep 6: Unfold the strip of paper and you will have a hollow cone shape.\nStep 7: Use glue or tape to hold the cone together and you have a háº¡c giáº¥y!\n\nNote: You can also use different shapes of paper to create different types of háº¡c, such as a háº¡c trÃ²n (round cone) or a háº¡c thuÃ´n (cone with a pointed tip).\n","output_type":"stream"}]},{"cell_type":"code","source":"input_text = \"LÃ m sao Ä‘á»ƒ khá»e máº¡nh?\"\n\n# Tokenize the input text\ninputs = tokenizer(input_text, return_tensors=\"pt\")\n\n# Generate response with max_new_tokens set\noutputs = model.generate(**inputs, max_new_tokens=300)\n\n# Decode and print the generated response\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T00:11:20.950274Z","iopub.execute_input":"2024-05-28T00:11:20.950864Z","iopub.status.idle":"2024-05-28T00:17:08.636830Z","shell.execute_reply.started":"2024-05-28T00:11:20.950817Z","shell.execute_reply":"2024-05-28T00:17:08.635826Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"LÃ m sao Ä‘á»ƒ khá»e máº¡nh?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]}]}
